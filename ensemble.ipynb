{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXdv6aZIaiuPpfpCD2ZMxD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110\n","!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-tf-plugin-cuda110"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRqiBkrHS-pG","executionInfo":{"status":"ok","timestamp":1669174843488,"user_tz":-540,"elapsed":45624,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"07fd84c4-619c-47d6-ada7-101d047257e3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://developer.download.nvidia.com/compute/redist\n","Collecting nvidia-dali-cuda110\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-dali-cuda110/nvidia_dali_cuda110-1.19.0-6205436-py3-none-manylinux2014_x86_64.whl (382.6 MB)\n","\u001b[K     |████████████████████████████████| 382.6 MB 42 kB/s \n","\u001b[?25hInstalling collected packages: nvidia-dali-cuda110\n","Successfully installed nvidia-dali-cuda110-1.19.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://developer.download.nvidia.com/compute/redist\n","Collecting nvidia-dali-tf-plugin-cuda110\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-dali-tf-plugin-cuda110/nvidia-dali-tf-plugin-cuda110-1.19.0.tar.gz (418 kB)\n","\u001b[K     |████████████████████████████████| 418 kB 706 kB/s \n","\u001b[?25hRequirement already satisfied: nvidia-dali-cuda110==1.19.0 in /usr/local/lib/python3.7/dist-packages (from nvidia-dali-tf-plugin-cuda110) (1.19.0)\n","Building wheels for collected packages: nvidia-dali-tf-plugin-cuda110\n","  Building wheel for nvidia-dali-tf-plugin-cuda110 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvidia-dali-tf-plugin-cuda110: filename=nvidia_dali_tf_plugin_cuda110-1.19.0-cp37-cp37m-linux_x86_64.whl size=120499 sha256=9f5a68dad5baad683d0e7b2bdf05e8ece94fb038625c33b696fff882872bd658\n","  Stored in directory: /root/.cache/pip/wheels/7f/8c/08/7adf9f8b758908640a1a1569489d8ab08a81a05192aa508363\n","Successfully built nvidia-dali-tf-plugin-cuda110\n","Installing collected packages: nvidia-dali-tf-plugin-cuda110\n","Successfully installed nvidia-dali-tf-plugin-cuda110-1.19.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POyv9G7H7_c9","executionInfo":{"status":"ok","timestamp":1669174873706,"user_tz":-540,"elapsed":30223,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"2579d357-edce-4093-817a-2e59a8fefb92"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import random as rn\n","import os\n","from sklearn.metrics import accuracy_score, f1_score\n","from keras.models import load_model\n","\n","import warnings\n","import logging\n","\n","logging.getLogger('tensorflow').disabled = True\n","warnings.filterwarnings(\"ignore\")\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"],"metadata":{"id":"WNf0nMX69mWb","executionInfo":{"status":"ok","timestamp":1669174876853,"user_tz":-540,"elapsed":3151,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from nvidia.dali.pipeline import Pipeline\n","import nvidia.dali.ops as ops\n","import nvidia.dali.fn as fn\n","import nvidia.dali.types as types\n","import nvidia.dali.tfrecord as tfrec\n","import nvidia.dali.plugin.tf as dali_tf"],"metadata":{"id":"ALV3YHgGS5i5","executionInfo":{"status":"ok","timestamp":1669174876854,"user_tz":-540,"elapsed":5,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def thresholdAccur(th, pred_test_data, true_test_data):\n","  if th ==0 :\n","    true_test_ls = []\n","    pred_test_ls = []\n","    for (true, pred) in zip(true_test, pred_test):\n","        true_test_ls.append(np.argmax(true))\n","        pred_test_ls.append(np.argmax(pred))\n","    argmax_acc = accuracy_score(true_test_ls, pred_test_ls)\n","    f1_micro = f1_score(true_test_ls, pred_test_ls, average='micro')\n","    print(\"thresholde :   - \",\" accuracy_score : \", argmax_acc, \" f1_score : \", f1_micro)\n","  else:\n","    pred = pred_test_data.copy()\n","    for ls in pred:\n","        thres = th\n","        pred[pred >= thres] = 1\n","        pred[pred < thres] = 0\n","    print(\"thresholde : \", th, \" accuracy_score : \", accuracy_score(true_test_data, pred), \" f1_score : \", f1_score(true_test_data, pred, average='micro'))\n"],"metadata":{"id":"5Hu13LZsEOLB","executionInfo":{"status":"ok","timestamp":1669175321612,"user_tz":-540,"elapsed":545,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["f_PATH = \"/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/\""],"metadata":{"id":"WXOd3IEsTUOE","executionInfo":{"status":"ok","timestamp":1669174877253,"user_tz":-540,"elapsed":403,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 6label"],"metadata":{"id":"i2Ehnfnc9KjG"}},{"cell_type":"code","source":["model1 = load_model(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/model/cnn_6.h5')\n","model2 = load_model(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/model/resnet_6.h5')"],"metadata":{"id":"CtUVZSSC5Uxb","executionInfo":{"status":"ok","timestamp":1669174891431,"user_tz":-540,"elapsed":14182,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["set_seed = 46\n","np.random.seed(set_seed)\n","rn.seed(set_seed)\n","tf.random.set_seed(set_seed)\n","label_test = pd.read_csv(f_PATH+'label/label_6_basic_emo_test.csv')\n","TEST_DATA_SIZE = label_test.shape[0]"],"metadata":{"id":"WWMXwVKqTggq","executionInfo":{"status":"ok","timestamp":1669175091143,"user_tz":-540,"elapsed":1004,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class TFRecordPipelineTest(Pipeline):\n","    def __init__(self, batch_size, num_threads,\n","                 device = 'cpu', device_id = 0):\n","        super(TFRecordPipelineTest, self).__init__(batch_size,\n","                                         num_threads,\n","                                         device_id)\n","        self.input = fn.readers.tfrecord(        \n","             features = {\"image_raw\": tfrec.FixedLenFeature((), tfrec.string, \"\"),\n","                         \"label\": tfrec.FixedLenFeature([6], tfrec.int64,  6)},\n","             path = [f_PATH+'tfrecords/6_basic_emo_test.tfrecords'],\n","             index_path = [f_PATH+'tfrecords/6_basic_emo_test.idx'],\n","             random_shuffle=False,\n","             seed = set_seed)\n","        self.iter = 0\n","    def define_graph(self):\n","        inputs = self.input\n","        images = fn.decoders.image(inputs[\"image_raw\"], device = \"mixed\", output_type = types.RGB) / 255.\n","        labels = inputs[\"label\"].gpu()\n","        return (images, labels)\n","    def iter_setup(self):\n","        pass"],"metadata":{"id":"FFXUE00l53GG","executionInfo":{"status":"ok","timestamp":1669175167434,"user_tz":-540,"elapsed":3,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    batch_size = 1\n","    shapes = ((batch_size, 64, 64, 3),\n","              (batch_size, 6))\n","    pipe_test = TFRecordPipelineTest(batch_size=batch_size,\n","                            num_threads=4,\n","                            device='gpu',\n","                            device_id=0)\n","    with tf.device('/gpu:0'):\n","    #with strategy.scope():        \n","        # Create dataset\n","        ds_test = dali_tf.DALIDataset(\n","            pipeline=pipe_test,\n","            batch_size=batch_size,\n","            output_shapes=shapes,\n","            output_dtypes=(tf.float32, tf.int64),\n","            device_id=0)\n","        loss, acc1 = model1.evaluate(ds_test, steps=TEST_DATA_SIZE)\n","        print(\"Test CNN accuracy:\", acc1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgpqVUHb550F","executionInfo":{"status":"ok","timestamp":1669175223786,"user_tz":-540,"elapsed":3648,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"9d18aad4-2c70-4cf3-d93a-0e07d46e6a4b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 3s 3ms/step - loss: 0.4088 - accuracy: 0.8510\n","Test CNN accuracy: 0.8510140180587769\n"]}]},{"cell_type":"code","source":["pred_test_cnn = model1.predict(ds_test.take(TEST_DATA_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-O74xatpmIam","executionInfo":{"status":"ok","timestamp":1669175226613,"user_tz":-540,"elapsed":2838,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"604d46bc-8052-435b-9b49-1dfad3ebfa9a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 3s 2ms/step\n"]}]},{"cell_type":"code","source":["# https://docs.nvidia.com/deeplearning/dali/user-guide/docs/plugins/tensorflow_plugin_api.html\n","if __name__ == \"__main__\":\n","    batch_size = 1\n","    shapes = ((batch_size, 64, 64, 3),\n","              (batch_size, 6))\n","    pipe_test = TFRecordPipelineTest(batch_size=batch_size,\n","                            num_threads=4,\n","                            device='gpu',\n","                            device_id=0)\n","    with tf.device('/gpu:0'):\n","        ds_test = dali_tf.DALIDataset(\n","            pipeline=pipe_test,\n","            batch_size=batch_size,\n","            output_shapes=shapes,\n","            output_dtypes=(tf.float32, tf.int64),\n","            device_id=0)\n","        loss, acc2 = model2.evaluate(ds_test, steps=TEST_DATA_SIZE)\n","        print(\"Test ResNet accuracy:\", acc2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o86HP76w-0sP","executionInfo":{"status":"ok","timestamp":1669175238423,"user_tz":-540,"elapsed":11840,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"adf96f89-e22e-4d4a-9f6f-3523d588ab3a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 12s 9ms/step - loss: 0.2066 - accuracy: 0.9750\n","Test ResNet accuracy: 0.975039005279541\n"]}]},{"cell_type":"code","source":["pred_test_resnet = model2.predict(ds_test.take(TEST_DATA_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBPwhjGZ8TXf","executionInfo":{"status":"ok","timestamp":1669175249193,"user_tz":-540,"elapsed":10801,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"8f6d5054-704f-4508-a843-b981de6dd9aa"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 10s 8ms/step\n"]}]},{"cell_type":"code","source":["pred_test = (pred_test_cnn * (acc1/(acc1+acc2)) )+(pred_test_resnet * (acc2/(acc1+acc2)))\n","true_test = np.concatenate([y for x, y in ds_test.take(TEST_DATA_SIZE)], axis=0)"],"metadata":{"id":"hHKVS0Pc_Pbo","executionInfo":{"status":"ok","timestamp":1669175253061,"user_tz":-540,"elapsed":1623,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["thresholdAccur(0, pred_test, true_test)\n","thresholdAccur(0.1, pred_test, true_test)\n","thresholdAccur(0.2, pred_test, true_test)\n","thresholdAccur(0.3, pred_test, true_test)\n","thresholdAccur(0.4, pred_test, true_test)\n","thresholdAccur(0.5, pred_test, true_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aoh15pl1DuBr","executionInfo":{"status":"ok","timestamp":1669175327534,"user_tz":-540,"elapsed":898,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"30675953-a336-4cce-ccb9-bc469ccd2e15"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["thresholde :   -   accuracy_score :  0.9750390015600624  f1_score :  0.9750390015600624\n","thresholde :  0.1  accuracy_score :  0.719188767550702  f1_score :  0.8585858585858585\n","thresholde :  0.2  accuracy_score :  0.8198127925117005  f1_score :  0.9087656529516994\n","thresholde :  0.3  accuracy_score :  0.8985959438377535  f1_score :  0.943593574897273\n","thresholde :  0.4  accuracy_score :  0.9500780031201248  f1_score :  0.9654112221368177\n","thresholde :  0.5  accuracy_score :  0.9703588143525741  f1_score :  0.9760690466849745\n"]}]},{"cell_type":"markdown","source":["# 22 label"],"metadata":{"id":"tYoLZOB6GDqv"}},{"cell_type":"code","source":["model1 = keras.models.load_model(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/model/cnn_22.h5')\n","model2 = keras.models.load_model(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/model/resnet_22.h5')"],"metadata":{"id":"asAo-58UGDqw","executionInfo":{"status":"ok","timestamp":1669175339037,"user_tz":-540,"elapsed":8771,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["class TFRecordPipelineTest(Pipeline):\n","    def __init__(self, batch_size, num_threads,\n","                 device = 'cpu', device_id = 0):\n","        super(TFRecordPipelineTest, self).__init__(batch_size,\n","                                         num_threads,\n","                                         device_id)\n","        self.input = fn.readers.tfrecord(        \n","             features = {\"image_raw\": tfrec.FixedLenFeature((), tfrec.string, \"\"),\n","                         \"label\": tfrec.FixedLenFeature([22], tfrec.int64,  22)},\n","             path = [f_PATH+'tfrecords/22_emo_test.tfrecords'],\n","             index_path = [f_PATH+'tfrecords/22_emo_test.idx'],\n","             random_shuffle=False,\n","             seed = set_seed)\n","        self.iter = 0\n","    def define_graph(self):\n","        inputs = self.input\n","        images = fn.decoders.image(inputs[\"image_raw\"], device = \"mixed\", output_type = types.RGB) / 255.\n","        labels = inputs[\"label\"].gpu()\n","        return (images, labels)\n","    def iter_setup(self):\n","        pass"],"metadata":{"id":"YyDPxd54GDqw","executionInfo":{"status":"ok","timestamp":1669175360233,"user_tz":-540,"elapsed":2,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    batch_size = 1\n","    shapes = ((batch_size, 64, 64, 3),\n","              (batch_size, 22))\n","    pipe_test = TFRecordPipelineTest(batch_size=batch_size,\n","                            num_threads=1,\n","                            device='gpu',\n","                            device_id=0)\n","    with tf.device('/gpu:0'):\n","        ds_test = dali_tf.DALIDataset(\n","            pipeline=pipe_test,\n","            batch_size=batch_size,\n","            output_shapes=shapes,\n","            output_dtypes=(tf.float32, tf.int64),\n","            device_id=0)\n","        print(ds_test)\n","        loss, acc1 = model1.evaluate(ds_test, steps=TEST_DATA_SIZE)\n","        print(\"Test CNN accuary: \", acc1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwTbfuR0GDqw","executionInfo":{"status":"ok","timestamp":1669175367342,"user_tz":-540,"elapsed":5096,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"f0f811a0-74b6-4603-92e5-305ed0282588"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["<DALIDataset element_spec=(TensorSpec(shape=(1, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(1, 22), dtype=tf.int64, name=None))>\n","1282/1282 [==============================] - 5s 3ms/step - loss: 0.7161 - accuracy: 0.8565\n","Test CNN accuary:  0.8564742803573608\n"]}]},{"cell_type":"code","source":["pred_test_cnn = model1.predict(ds_test.take(TEST_DATA_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9BAhZyKmuZv","executionInfo":{"status":"ok","timestamp":1669175383281,"user_tz":-540,"elapsed":3815,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"e70f83a5-808d-433b-e765-43577549dc0f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 3s 2ms/step\n"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    batch_size = 1\n","    shapes = ((batch_size, 64, 64, 3),\n","              (batch_size, 22))\n","    pipe_test = TFRecordPipelineTest(batch_size=batch_size,\n","                            num_threads=1,\n","                            device='gpu',\n","                            device_id=0)\n","    with tf.device('/gpu:0'):\n","        ds_test = dali_tf.DALIDataset(\n","            pipeline=pipe_test,\n","            batch_size=batch_size,\n","            output_shapes=shapes,\n","            output_dtypes=(tf.float32, tf.int64),\n","            device_id=0)\n","        print(ds_test)\n","        loss, acc2 = model2.evaluate(ds_test, steps=TEST_DATA_SIZE)\n","        print(\"Test ResNet accuary: \", acc2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8VErMjfGDqw","executionInfo":{"status":"ok","timestamp":1669175411979,"user_tz":-540,"elapsed":12393,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"4a2d207a-0d86-4946-ed6d-bebf9f55c337"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["<DALIDataset element_spec=(TensorSpec(shape=(1, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(1, 22), dtype=tf.int64, name=None))>\n","1282/1282 [==============================] - 12s 9ms/step - loss: 0.4175 - accuracy: 0.9470\n","Test ResNet accuary:  0.9469578862190247\n"]}]},{"cell_type":"code","source":["pred_test_resnet = model2.predict(ds_test.take(TEST_DATA_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDIalzlDGDqw","executionInfo":{"status":"ok","timestamp":1669175423929,"user_tz":-540,"elapsed":11964,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"3e43007a-bda3-4b5b-ac59-5a1afd0d2c41"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 12s 8ms/step\n"]}]},{"cell_type":"code","source":["pred_test = (pred_test_cnn * (acc1/(acc1+acc2)) )+(pred_test_resnet * (acc2/(acc1+acc2)))\n","true_test = np.concatenate([y for x, y in ds_test.take(TEST_DATA_SIZE)], axis=0)"],"metadata":{"id":"EQVTUIbHGDqw","executionInfo":{"status":"ok","timestamp":1669175426156,"user_tz":-540,"elapsed":994,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["thresholdAccur(0, pred_test, true_test)\n","thresholdAccur(0.1, pred_test, true_test)\n","thresholdAccur(0.2, pred_test, true_test)\n","thresholdAccur(0.3, pred_test, true_test)\n","thresholdAccur(0.4, pred_test, true_test)\n","thresholdAccur(0.5, pred_test, true_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THUqE2OAGDqx","executionInfo":{"status":"ok","timestamp":1669175426664,"user_tz":-540,"elapsed":511,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"ba86c6b6-246e-45db-9fb8-5fa20e17753a"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["thresholde :   -   accuracy_score :  0.9438377535101404  f1_score :  0.9438377535101404\n","thresholde :  0.1  accuracy_score :  0.7831513260530422  f1_score :  0.8638888888888889\n","thresholde :  0.2  accuracy_score :  0.8361934477379095  f1_score :  0.8938021022109459\n","thresholde :  0.3  accuracy_score :  0.87597503900156  f1_score :  0.9129464285714285\n","thresholde :  0.4  accuracy_score :  0.905616224648986  f1_score :  0.9290076335877863\n","thresholde :  0.5  accuracy_score :  0.9391575663026521  f1_score :  0.9499013806706114\n"]}]},{"cell_type":"markdown","source":["# multi label"],"metadata":{"id":"OLeWMsHQHEFM"}},{"cell_type":"code","source":["model1 = keras.models.load_model(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/model/cnn_multi.h5')\n","model2 = keras.models.load_model(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/model/resnet_multi.h5')"],"metadata":{"id":"Ft97UtIDHEFR","executionInfo":{"status":"ok","timestamp":1669175441301,"user_tz":-540,"elapsed":5929,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["class TFRecordPipelineTest(Pipeline):\n","    def __init__(self, batch_size, num_threads,\n","                 device = 'cpu', device_id = 0):\n","        super(TFRecordPipelineTest, self).__init__(batch_size,\n","                                         num_threads,\n","                                         device_id)\n","        self.input = fn.readers.tfrecord(        \n","             features = {\"image_raw\": tfrec.FixedLenFeature((), tfrec.string, \"\"),\n","                         \"label\": tfrec.FixedLenFeature([24], tfrec.int64,  24)},\n","             path = [f_PATH+'tfrecords/multi-label_test.tfrecords'],\n","             index_path = [f_PATH+'tfrecords/multi-label_test.idx'],\n","             random_shuffle=False,\n","             seed = set_seed)\n","        self.iter = 0\n","    def define_graph(self):\n","        inputs = self.input\n","        images = fn.decoders.image(inputs[\"image_raw\"], device = \"mixed\", output_type = types.RGB) / 255.\n","        labels = inputs[\"label\"].gpu()\n","        return (images, labels)\n","    def iter_setup(self):\n","        pass"],"metadata":{"id":"MuQ2-81sHEFR","executionInfo":{"status":"ok","timestamp":1669175471456,"user_tz":-540,"elapsed":3,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    batch_size = 1\n","    shapes = ((batch_size, 64, 64, 3),\n","              (batch_size, 24))\n","    pipe_test = TFRecordPipelineTest(batch_size=batch_size,\n","                            num_threads=4,\n","                            device='gpu',\n","                            device_id=0)\n","    with tf.device('/gpu:0'):\n","    #with strategy.scope():        \n","        # Create dataset\n","        ds_test = dali_tf.DALIDataset(\n","            pipeline=pipe_test,\n","            batch_size=batch_size,\n","            output_shapes=shapes,\n","            output_dtypes=(tf.float32, tf.int64),\n","            device_id=0)\n","        loss, acc1 = model1.evaluate(ds_test, steps=TEST_DATA_SIZE)\n","        print(\"Test CNN accuary: \", acc1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1p8nLDCEHEFR","executionInfo":{"status":"ok","timestamp":1669175481800,"user_tz":-540,"elapsed":8019,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"37cd67e6-c1a4-4b13-b494-2a5a31b7beab"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 8s 5ms/step - loss: 0.0738 - accuracy: 0.6147\n","Test CNN accuary:  0.614664614200592\n"]}]},{"cell_type":"code","source":["pred_test_cnn = model1.predict(ds_test.take(TEST_DATA_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrqMOKvxnIfa","executionInfo":{"status":"ok","timestamp":1669175485463,"user_tz":-540,"elapsed":3677,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"349742b3-b381-48e9-cea0-de5ca945f8ec"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 3s 3ms/step\n"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    batch_size = 1\n","    shapes = ((batch_size, 64, 64, 3),\n","              (batch_size, 24))\n","    pipe_test = TFRecordPipelineTest(batch_size=batch_size,\n","                            num_threads=4,\n","                            device='gpu',\n","                            device_id=0)\n","    with tf.device('/gpu:0'):\n","    #with strategy.scope():        \n","        # Create dataset\n","        ds_test = dali_tf.DALIDataset(\n","            pipeline=pipe_test,\n","            batch_size=batch_size,\n","            output_shapes=shapes,\n","            output_dtypes=(tf.float32, tf.int64),\n","            device_id=0)\n","        loss, acc2 = model2.evaluate(ds_test, steps=TEST_DATA_SIZE)\n","        print(\"Test ResNet accuary: \", acc2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP5c9W-xHEFS","executionInfo":{"status":"ok","timestamp":1669175497704,"user_tz":-540,"elapsed":12270,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"281389bc-19b8-4863-8ff3-f10850b94c8d"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 13s 9ms/step - loss: 0.0355 - accuracy: 0.8003\n","Test ResNet accuary:  0.8003120422363281\n"]}]},{"cell_type":"code","source":["pred_test_resnet = model2.predict(ds_test.take(TEST_DATA_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNk48TFcHEFS","executionInfo":{"status":"ok","timestamp":1669175509655,"user_tz":-540,"elapsed":11963,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"a36a534f-90bd-4d9b-e1ec-60da042b0e96"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["1282/1282 [==============================] - 11s 8ms/step\n"]}]},{"cell_type":"code","source":["pred_test = (pred_test_cnn * (acc1/(acc1+acc2)) )+(pred_test_resnet * (acc2/(acc1+acc2)))\n","true_test = np.concatenate([y for x, y in ds_test.take(TEST_DATA_SIZE)], axis=0)"],"metadata":{"id":"2N18lCnRHEFS","executionInfo":{"status":"ok","timestamp":1669175510132,"user_tz":-540,"elapsed":513,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["thresholdAccur(0, pred_test, true_test)\n","thresholdAccur(0.1, pred_test, true_test)\n","thresholdAccur(0.2, pred_test, true_test)\n","thresholdAccur(0.3, pred_test, true_test)\n","thresholdAccur(0.4, pred_test, true_test)\n","thresholdAccur(0.5, pred_test, true_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRcKJa3BHEFS","executionInfo":{"status":"ok","timestamp":1669175511179,"user_tz":-540,"elapsed":1051,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"2c8c0df2-cc47-4100-c023-da1a38be7bfe"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["thresholde :   -   accuracy_score :  0.7418096723868954  f1_score :  0.7418096723868954\n","thresholde :  0.1  accuracy_score :  0.7581903276131046  f1_score :  0.8871315600287561\n","thresholde :  0.2  accuracy_score :  0.8260530421216848  f1_score :  0.9127382146439317\n","thresholde :  0.3  accuracy_score :  0.8517940717628705  f1_score :  0.9239494715132767\n","thresholde :  0.4  accuracy_score :  0.8712948517940717  f1_score :  0.9357992073976222\n","thresholde :  0.5  accuracy_score :  0.859594383775351  f1_score :  0.9308655416439847\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TKKjd88znLba"},"execution_count":null,"outputs":[]}]}