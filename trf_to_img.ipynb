{"cells":[{"cell_type":"markdown","metadata":{"id":"xiT1eWl6YfhZ"},"source":["# tfrecords --> images & Analyze image labels"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjDkvqKLfGFd","outputId":"499e4b75-f1b8-4e96-8b38-cdb007184e5d","executionInfo":{"status":"ok","timestamp":1668951763754,"user_tz":-540,"elapsed":2040,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install ipython-autotime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4GgckCPZNSa","outputId":"69766b73-dec5-4c6f-e085-3b114c651156","executionInfo":{"status":"ok","timestamp":1668951769513,"user_tz":-540,"elapsed":5761,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (7.9.0)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.18.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.0.10)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.2.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wrw4xdJDYfhc","executionInfo":{"status":"ok","timestamp":1668951776163,"user_tz":-540,"elapsed":6652,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","import random as rn\n","import numpy as np\n","from collections import Counter\n","from IPython.display import display, Image\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3l_XyWQYfhd","outputId":"3198b3e1-e0d6-48bf-8b29-cb6078d658da","executionInfo":{"status":"ok","timestamp":1668951776164,"user_tz":-540,"elapsed":5,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.01 ms (started: 2022-11-20 13:42:55 +00:00)\n"]}],"source":["# Record cell run time.\n","#!pip install ipython-autotime\n","\n","%load_ext autotime"]},{"cell_type":"markdown","metadata":{"id":"AFczW1gJYfhe"},"source":["## 1. tfrecord --> images"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-i_C407LYfhf","outputId":"d29a2ad6-29e4-4ff7-eaff-a5f83d4bf4a0","executionInfo":{"status":"ok","timestamp":1668951776164,"user_tz":-540,"elapsed":4,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 6.86 ms (started: 2022-11-20 13:42:55 +00:00)\n"]}],"source":["# 딕셔너리화\n","image_feature_description = {\n","    'height': tf.io.FixedLenFeature([], tf.int64),\n","    'width': tf.io.FixedLenFeature([], tf.int64),\n","    'depth': tf.io.FixedLenFeature([], tf.int64),\n","    'label': tf.io.FixedLenFeature([24], tf.int64), \n","    'image_raw': tf.io.FixedLenFeature([], tf.string),\n","}\n","\n","     # adjust the number with [6, 22, 24] labels (6_basic_emo, 22_emo, multi-label)\n","\n","# 사전을 이용하여 입력 tf.Example 프로토를 구문 분석\n","def _parse_image_function(example_proto):\n","    return tf.io.parse_single_example(example_proto, image_feature_description)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZDtMUF1Yfhf","outputId":"3e278e33-dbbd-4dc6-fd59-adf8bf5c56af","executionInfo":{"status":"ok","timestamp":1668952029383,"user_tz":-540,"elapsed":688,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1282\n","time: 573 ms (started: 2022-11-20 13:47:08 +00:00)\n"]}],"source":["# tfrecord 파일을 불러옴\n","raw_image_dataset = tf.data.TFRecordDataset('/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/tfrecords/6_basic_emo_test.tfrecords')\n","\n","parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n","parsed_image_dataset\n","\n","df_label = pd.read_csv(f'/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/label/label_6_basic_emo_test.csv')\n","\n","dict_label = {}\n","for idx, row in df_label.iterrows():\n","    # print(row)\n","    dict_label[row['img_id']] = list(row['angry':'sad'].values)\n","print(len(dict_label))\n","\n","li_label = list(dict_label.keys())"]},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtugIV0-0RHn","executionInfo":{"status":"ok","timestamp":1668952044611,"user_tz":-540,"elapsed":3,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"65fb1dc5-b4da-4fda-e728-6740cb61c0ef"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 538 µs (started: 2022-11-20 13:47:24 +00:00)\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","n = 0\n","for image_features in parsed_image_dataset.take(3):\n","    image_raw = image_features['image_raw'].numpy()\n","    test = np.frombuffer(image_raw , dtype= np.uint8)\n","    test_cv =cv2.imdecode(test, cv2.IMREAD_COLOR)\n","    # print(type(test_cv))\n","    print(n)\n","    cv2.imwrite(PATH+'image/'+\"6\"+'/'+\"test\"+'/'+li_label[n], test_cv)\n","    n += 1\n","print(\"Number of images displayed:\", n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"aAqRIYMTxIvh","executionInfo":{"status":"error","timestamp":1668952076322,"user_tz":-540,"elapsed":290,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"f45b2bf5-c081-49e3-fc5e-ef9dc3c8bee3"},"execution_count":20,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-be7703673cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_image_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimage_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_raw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_raw\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Key: label.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]"]},{"output_type":"stream","name":"stdout","text":["time: 156 ms (started: 2022-11-20 13:47:55 +00:00)\n"]}]},{"cell_type":"code","source":["!cd /content/drive/MyDrive/facial_emotion_recognition_using_K-drama_dataset-main/image\n","!pwd"],"metadata":{"id":"3rS5bAZn0sNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668947927183,"user_tz":-540,"elapsed":427,"user":{"displayName":"yewon choi","userId":"13185614265759869235"}},"outputId":"b17d6428-3ccd-4543-d0bb-38afe7eadc37"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","time: 306 ms (started: 2022-11-20 12:38:46 +00:00)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"sjz_iwjVC-W5"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}